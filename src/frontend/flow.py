from src.app.llm import LiteLLMKit
import streamlit as st
from dotenv import load_dotenv
import os
from src.analysis.customer_discoverer import get_customer_discoverer
from src.analysis.market_analysis import get_market_report


load_dotenv()

# Initialize the LLM client
client = LiteLLMKit(model_name="gpt-4o", temperature=0.7, max_tokens=1024, stream=False)

# Define the sequential functions for the conversation flow
async def get_topic_step() -> str:
    return "Which market would you like to analyse?"

async def analysis_step(analysis_topic:str) -> str:
    report, graph = await get_market_report
    return report, graph



def get_steps():
    # List of steps in the flow
    return [get_topic_step, analysis_step]

# Maintain current state
if "current_step" not in st.session_state:
    st.session_state.current_step = 0

async def handle_conversation(prompt: str, history: list) -> str:
    """
    Handles the conversation logic with sequential flow and error handling.

    Args:
        prompt (str): User's input message.
        history (list): Chat history containing previous messages.

    Returns:
        str: Response generated by the assistant.
    """
    try:
        # Check if we're within the bounds of the flow
        if st.session_state.current_step < len(conversation_flow):
            # Get the current function and execute it
            current_function = conversation_flow[st.session_state.current_step]
            response = current_function(history)
            
            # If the step succeeds, move to the next step
            st.session_state.current_step += 1
        else:
            # Default response if flow completes
            response = "You've completed the flow! What else can I help with?"
        
        return response
    
    except Exception as e:
        # On error, reset the conversation to the first step
        st.session_state.current_step = 0
        return "An error occurred. Restarting the conversation. Please try again."

# Example function to simulate error (for testing)
def step_with_error(history: list) -> str:
    raise ValueError("Simulated error")
