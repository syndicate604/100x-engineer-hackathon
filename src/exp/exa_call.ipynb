{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "CUR_DIR = os.getcwd()\n",
    "CUR_DIR = CUR_DIR.replace(\"\\\\\", \"/\").replace('/exp','')\n",
    "sys.path.append(CUR_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from app.exa import ExaAPI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "exa_api = ExaAPI(api_key=os.getenv(\"EXA_API_KEY\"))\n",
    "\n",
    "results = exa_api.search(\"artificial intelligence news\", type=\"neural\", num_results=5)\n",
    "\n",
    "contents = exa_api.get_contents(\n",
    "    [\"https://www.theverge.com/2023/11/22/23973354/a-recent-openai-breakthrough-on-the-path-to-agi-has-caused-a-stir\"]\n",
    ")\n",
    "\n",
    "# Combined search and contents\n",
    "search_contents = exa_api.search_and_contents(\n",
    "    \"latest AI developments\", type=\"neural\", num_results=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://www.theverge.com/2023/11/22/23973354/a-recent-openai-breakthrough-on-the-path-to-agi-has-caused-a-stir',\n",
       " 'id': 'https://www.theverge.com/2023/11/22/23973354/a-recent-openai-breakthrough-on-the-path-to-agi-has-caused-a-stir',\n",
       " 'title': 'A recent OpenAI breakthrough on the path to AGI has caused a stir.',\n",
       " 'score': 0.19478736817836761,\n",
       " 'published_date': '2023-11-22T00:00:00.000Z',\n",
       " 'author': 'Alex Heath; Richard Lawler',\n",
       " 'image': None,\n",
       " 'subpages': None,\n",
       " 'extras': None,\n",
       " 'text': None,\n",
       " 'highlights': None,\n",
       " 'highlight_scores': None,\n",
       " 'summary': None}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.results[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A recent OpenAI breakthrough on the path to AGI has caused a stir. Reports from  Reuters  and  The Information  Wednesday night detail an OpenAI model called Q* (pronounced Q Star) that was recently demonstrated internally and is capable of solving simple math problems. Doing grade school math may not seem impressive, but the reports note that, according to the researchers involved, it could be a step toward creating artificial general intelligence (AGI). After the publishing of the Reuters report, which said senior exec Mira Murati told employees that a letter about Q* “precipitated the board’s actions” to fire Sam Altman last week, OpenAI spokesperson Lindsey Held Bolton refuted that notion in a statement shared with The Verge: “Mira told employees what the media reports were about but she did not comment on the accuracy of the information.” Separately, a person familiar with the matter told The Verge that the board never received a letter about such a breakthrough and that the company’s research progress didn’t play a role in Altman’s sudden firing. The drama continues!'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents.results[0].__dict__['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Result(url='https://www.technologyreview.com/2024/10/23/1105192/ai-hype-index-nov-dec-2024/', id='https://www.technologyreview.com/2024/10/23/1105192/ai-hype-index-nov-dec-2024/', title='Introducing: The AI Hype Index', score=None, published_date='2024-10-23T00:00:00.000Z', author='The Editors', image=None, subpages=None, extras=None, text='Everything you need to know about the state of AI.            There’s no denying that the AI industry moves fast. Each week brings a bold new announcement, product release, or lofty claim that pushes the bounds of what we previously thought was possible. Separating AI fact from hyped-up fiction isn’t always easy. That’s why we’ve created the AI Hype Index—a simple, at-a-glance summary of everything you need to know about the state of the industry. Our first index is a white-knuckle ride that ranges from the outright depressing—rising numbers of sexually explicit deepfakes; the complete lack of rules governing Elon Musk’s Grok AI model—to the bizarre, including AI-powered dating wingmen and startup Friend’s dorky intelligent-jewelry line.  But it’s not all a horror show—at least not entirely. AI is being used for more wholesome endeavors, too, like simulating the classic video game Doom without a traditional gaming engine. Elsewhere, AI models have gotten so good at table tennis they can now beat beginner-level human opponents. They’re also giving us essential insight into the secret names monkeys use to communicate with one another. Because while AI may be a lot of things, it’s never boring.      Deep Dive   Artificial intelligence    Stay connected       Get the latest updates fromMIT Technology Review Discover special offers, top stories,\\nupcoming events, and more.', highlights=None, highlight_scores=None, summary=None),\n",
       " Result(url='https://akhaliq.substack.com/p/trending-ai-news-stories-papers-e68', id='https://akhaliq.substack.com/p/trending-ai-news-stories-papers-e68', title='Trending AI news stories + papers', score=None, published_date='2023-05-15T18:15:20.000Z', author='AK', image='https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4f8171c9-69e0-4f9e-a621-dfb00efb7c08_1454x1088.jpeg', subpages=None, extras=None, text=\"Sponsor      Amazon is focusing on using A.I. to get stuff delivered to you faster     Hugging Face releases the first RNN in transformers!      C3.ai stock pops, company raises outlook amid 'accelerating' AI interest     Willow - A Practical, Open Source, Privacy-Focused Platform for Voice Assistants and other Applications     Qualcomm CEO: ‘A.I. is going to touch every corner of our lives. Here’s how our devices will change to make it happen’       MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers abs:  https://arxiv.org/abs/2305.07185     paper page:  https://huggingface.co/papers/2305.07185  abstract: Autoregressive transformers are spectacular models for short sequences but scale poorly to long sequences such as high-resolution images, podcasts, code, or books. We proposed Megabyte, a multi-scale decoder architecture that enables end-to-end differentiable modeling of sequences of over one million bytes. Megabyte segments sequences into patches and uses a local submodel within patches and a global model between patches. This enables sub-quadratic self-attention, much larger feedforward layers for the same compute, and improved parallelism during decoding -- unlocking better performance at reduced cost for both training and generation. Extensive experiments show that Megabyte allows byte-level models to perform competitively with subword models on long context language modeling, achieve state-of-the-art density estimation on ImageNet, and model audio from raw files. Together, these results establish the viability of tokenization-free autoregressive sequence modeling at scale.             ArtGPT-4: Artistic Vision-Language Understanding with Adapter-enhanced MiniGPT-4   abs:  https://arxiv.org/abs/2305.07490     paper page:  https://huggingface.co/papers/2305.07490   model:  https://huggingface.co/Tyrannosaurus/ArtGPT-4  abstract: In recent years, large language models (LLMs) have made significant progress in natural language processing (NLP), with models like ChatGPT and GPT-4 achieving impressive capabilities in various linguistic tasks. However, training models on such a large scale is challenging, and finding datasets that match the model's scale is often difficult. Fine-tuning and training models with fewer parameters using novel methods have emerged as promising approaches to overcome these challenges. One such model is MiniGPT-4, which achieves comparable vision-language understanding to GPT-4 by leveraging novel pre-training models and innovative training strategies. However, the model still faces some challenges in image understanding, particularly in artistic pictures. A novel multimodal model called ArtGPT-4 has been proposed to address these limitations. ArtGPT-4 was trained on image-text pairs using a Tesla A100 device in just 2 hours, using only about 200 GB of data. The model can depict images with an artistic flair and generate visual code, including aesthetically pleasing HTML/CSS web pages. Furthermore, the article proposes novel benchmarks for evaluating the performance of vision-language models. In the subsequent evaluation methods, ArtGPT-4 scored more than 1 point higher than the current state-of-the-art model and was only 0.25 points lower than artists on a 6-point scale.             Optimizing Memory Mapping Using Deep Reinforcement Learning   abs:  https://arxiv.org/abs/2305.07440     paper page:  https://huggingface.co/papers/2305.07440  abstract: Resource scheduling and allocation is a critical component of many high impact systems ranging from congestion control to cloud computing. Finding more optimal solutions to these problems often has significant impact on resource and time savings, reducing device wear-and-tear, and even potentially improving carbon emissions. In this paper, we focus on a specific instance of a scheduling problem, namely the memory mapping problem that occurs during compilation of machine learning programs: That is, mapping tensors to different memory layers to optimize execution time. We introduce an approach for solving the memory mapping problem using Reinforcement Learning. RL is a solution paradigm well-suited for sequential decision making problems that are amenable to planning, and combinatorial search spaces with high-dimensional data inputs. We formulate the problem as a single-player game, which we call the mallocGame, such that high-reward trajectories of the game correspond to efficient memory mappings on the target hardware. We also introduce a Reinforcement Learning agent, mallocMuZero, and show that it is capable of playing this game to discover new and improved memory mapping solutions that lead to faster execution times on real ML workloads on ML accelerators. We compare the performance of mallocMuZero to the default solver used by the Accelerated Linear Algebra (XLA) compiler on a benchmark of realistic ML workloads. In addition, we show that mallocMuZero is capable of improving the execution time of the recently published AlphaTensor matrix multiplication model.             Universal Source Separation with Weakly Labelled Data   abs:  https://arxiv.org/abs/2305.07447     paper page:  https://huggingface.co/papers/2305.07447   github:  https://github.com/bytedance/uss  abstract: Universal source separation (USS) is a fundamental research task for computational auditory scene analysis, which aims to separate mono recordings into individual source tracks. There are three potential challenges awaiting the solution to the audio source separation task. First, previous audio source separation systems mainly focus on separating one or a limited number of specific sources. There is a lack of research on building a unified system that can separate arbitrary sources via a single model. Second, most previous systems require clean source data to train a separator, while clean source data are scarce. Third, there is a lack of USS system that can automatically detect and separate active sound classes in a hierarchical level. To use large-scale weakly labeled/unlabeled audio data for audio source separation, we propose a universal audio source separation framework containing: 1) an audio tagging model trained on weakly labeled data as a query net; and 2) a conditional source separation model that takes query net outputs as conditions to separate arbitrary sound sources. We investigate various query nets, source separation models, and training strategies and propose a hierarchical USS strategy to automatically detect and separate sound classes from the AudioSet ontology. By solely leveraging the weakly labelled AudioSet, our USS system is successful in separating a wide variety of sound classes, including sound event separation, music source separation, and speech enhancement. The USS system achieves an average signal-to-distortion ratio improvement (SDRi) of 5.57 dB over 527 sound classes of AudioSet; 10.57 dB on the DCASE 2018 Task 2 dataset; 8.12 dB on the MUSDB18 dataset; an SDRi of 7.28 dB on the Slakh2100 dataset; and an SSNR of 9.00 dB on the voicebank-demand dataset.             Better speech synthesis through scaling   abs:  https://arxiv.org/abs/2305.07243     paper page:  https://huggingface.co/papers/2305.07243  abstract: In recent years, the field of image generation has been revolutionized by the application of autoregressive transformers and DDPMs. These approaches model the process of image generation as a step-wise probabilistic processes and leverage large amounts of compute and data to learn the image distribution. This methodology of improving performance need not be confined to images. This paper describes a way to apply advances in the image generative domain to speech synthesis. The result is TorToise -- an expressive, multi-voice text-to-speech system.            Thank you for reading AK’s Substack. This post is public so feel free to share it.   Share\", highlights=None, highlight_scores=None, summary=None),\n",
       " Result(url='https://radicaldatascience.wordpress.com/2024/09/16/ai-news-briefs-bulletin-board-for-september-2024/', id='https://radicaldatascience.wordpress.com/2024/09/16/ai-news-briefs-bulletin-board-for-september-2024/', title='AI News Briefs BULLETIN BOARD for September\\xa02024', score=None, published_date='2024-09-16T00:00:00.000Z', author='', image=None, subpages=None, extras=None, text='Welcome to the AI News Briefs Bulletin Board, a timely new channel bringing you the latest industry insights and perspectives surrounding the field of AI including deep learning, large language models, generative AI, and transformers. I am working tirelessly to dig up the most timely and curious tidbits underlying the day’s most popular technologies. I know this field is advancing rapidly and I want to bring you a regular resource to keep you informed and state-of-the-art. The news bites are constantly being added in reverse date order (most recent on top). With the bulletin board you can check back often to see what’s happening in our rapidly accelerating industry. Click HERE to check out previous “AI News Briefs” round-ups.\\n    \\n    \\n[9/17/2024] Google Launched NotebookLM with AI-Powered Audio Podcast and Summaries – NotebookLM is Google Labs’ new tool that converts uploaded documents into AI-generated audio discussions in podcast format. It transforms text from PDFs, Google Docs, and Slides into podcast-style conversations between two AI hosts. This approach aims to enhance information retention through auditory learning.\\nThe system uses Gemini 1.5’s multimodal capabilities to process various input formats. It analyzes content, extracts key information, and generates responses grounded in the source material. The system employs advanced text-to-speech synthesis for AI host voices. It generates contextually relevant dialogue, maintaining coherence with source material. However, occasional inaccuracies may occur, and user interaction during playback is not yet supported. NotebookLM provides citations and relevant quotes to support its outputs. Audio Overview’s core innovation lies in its AI-driven dialogue synthesis. The system creates a conversational summary of uploaded content, with AI agents discussing main points and connecting topics. \\nReported technical specifications:\\nContext window capacity: ~50 PDFs\\nLanguage support: Currently English-only\\nInput formats: PDFs, Google Docs, Slides, web URLs\\nOutput: Downloadable audio file\\nNotebookLM’s architecture manages large input volumes and cross-references information between multiple documents. \\nHowever, audio generation for extensive notebooks can take several minutes, indicating computational intensity.\\n    \\n[9/17/2024] NEW research paper: “LLMs Will Always Hallucinate, and We Need to Live With This.” – LLMs inevitably hallucinate due to fundamental mathematical and logical limitations. The paper proves hallucinations are structural and cannot be eliminated through architectural improvements, dataset enhancements, or fact-checking mechanisms.\\nThe authors introduce the concept of “Structural Hallucinations” and provide mathematical proofs using computational theory and Gödel’s First Incompleteness Theorem. They demonstrate undecidability in key LLM processes: training data completeness, information retrieval, intent classification, output generation, and fact-checking.\\nThe paper proves that every stage of LLM processing has a non-zero probability of producing hallucinations. It illustrates these concepts using popular LLMs (OpenAI, Gemini, Claude) on a specific prompt, showing deviation from expected responses.\\n    \\n[9/17/2024] NEW research paper: “What is the Role of Small Models in the LLM Era: A Survey,” – This paper explores the role of small models in the era of LLMs. It addresses the challenges of high computational costs and energy consumption associated with large models, which limit their accessibility for many researchers and businesses. The paper investigates how small models can complement or compete with LLMs in various scenarios.\\nThe authors systematically examine the relationship between LLMs and small models from two perspectives: collaboration and competition. They analyze how small models can enhance LLMs in tasks like data curation, efficient inference, and deficiency repair. Conversely, they explore how LLMs can improve small models through knowledge distillation and data synthesis.\\nThe research reveals that small models remain highly popular, with BERT-base being one of the most downloaded models. It identifies scenarios where small models are preferable, such as computation-constrained environments, task-specific applications, and situations requiring interpretability. The paper provides valuable insights for practitioners on optimizing resource usage and developing cost-effective systems.\\n    \\n    \\n[9/17/2024] CalypsoAI just launched a new, cybercrime-solving game called “Behind the Mask.” The desktop game showcases the power of CalypsoAI’s GenAI scanners and gives consumers the unique opportunity to interact with CalypsoAI’s technology and GenAI in a fun and compelling way.\\nThe premise of the game is that YOU are the investigator, trying to identify all the five hackers stealing valuable cryptocurrency—CalyptoCoins. Good news: you have the help of an AI informant. You must ask it the right questions to identify and stop the theft before more CalyptoCoins are lost. But there’s a twist… The hackers are using CalypsoAI’s technology to protect that information, and the GenAI scanners learn from each “leak” and improve defenses—making each level harder than the last. So, can you outsmart AI?\\n    \\n[9/16/2024] AI is accelerating the climate crisis – If you care about the environment, think twice about using AI. Generative artificial intelligence uses 30 times more energy than a traditional search engine, warns researcher Sasha Luccioni, on a mission to raise awareness about the environmental impact of the hot new technology.\\n    \\n    \\n[9/16/2024] At its Dreamforce conference in San Francisco this week, Salesforce Ventures announced an additional $500 million fund dedicated to AI companies, bringing its total AI investment fund to $1 billion. This marks a significant increase, as Salesforce Ventures doubled its AI fund to $500 million in June 2023.\\nSince its launch in 2009, Salesforce Ventures has deployed $5 billion, and its growing AI portfolio includes notable companies like Anthropic, Hugging Face, Runway, and Together AI. San Francisco’s AI boom is attracting startups from around the world, with Salesforce Ventures playing a key role in fostering the city’s AI ecosystem.\\n    \\n[9/16/2024] Jeff Dean, on the long term potential of multi-modal models like Gemini – Learn about Google’s AI journey from Jeff Dean. Explore the evolution of neural networks, Google Brain, and DeepMind. Discover insights on large-scale model training, reinforcement learning, and multimodal AI. Understand the development of Transformers and Gemini. Gain knowledge on cutting-edge AI techniques and their practical applications.\\n \\n \\n \\n    \\n[9/16/2024] Tweet by Astrophysics Ph.D. goes viral demoing Open AI Strawberry model replicated 10 months of Ph.D. coding work in ~ 6 prompts using paper’s methods section – Dr. Kyle Kabasares found that after about 6 prompts, ChatGPT o1’s preview and mini created a running version of the code described from the methods section of his research paper. He emphasizes that while the skeletal code does emulate what his actual code does, it did use its own synthetic data that he asked for it to create as opposed to real astronomical data that would be used in a real paper. Nevertheless, the potential it has is incredible to effectively accomplish what he struggled for about 10 months in the first year of his Ph.D. at UC Irvine (measuring black hole masses by modeling astronomical data).', highlights=None, highlight_scores=None, summary=None)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_contents.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
